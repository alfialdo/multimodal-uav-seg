{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# import argparse\n",
    "import numpy as np\n",
    "import PIL.Image as Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "from dataset.voc_2012 import VOC2012DatasetSemantic as VOC2012Dataset\n",
    "from model.vanilla_unet import VanillaUNet\n",
    "from trainer import train_one_epoch\n",
    "from eval import evaluate\n",
    "from utils import EarlyStopper\n",
    "from utils import saveModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = '/mnt/hdd/dataset/VOCdevkit/VOC2012'\n",
    "IMAGE_PATH = 'JPEGImages'\n",
    "SEMANTIC_MASK_PATH = 'SegmentationClass'\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "NUM_EPOCHS = 3\n",
    "LEARNING_RATE = 0.0001\n",
    "GPU_ID = 1\n",
    "\n",
    "NUM_CLASSES = 21\n",
    "NUM_WORKER = 10\n",
    "\n",
    "SCH_FACTOR = 0.15\n",
    "SCH_PATIENCE = 15\n",
    "SCH_COOLDOWN = 5\n",
    "\n",
    "ES_PATIENCE = 30\n",
    "ES_MIN_DELTA = 0.001\n",
    "ES_MODE = \"min\"\n",
    "\n",
    "BEST_TRAIN_LOSS = float('inf')\n",
    "BEST_VAL_LOSS = float('inf')\n",
    "\n",
    "SEL_CRITERION = \"CrossEntropyLoss\"\n",
    "SEL_OPTIMIZER = \"AdamW\"\n",
    "SEL_SCHEDULER = \"ReduceLROnPlateau\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor()\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = VOC2012Dataset(DATASET_PATH, IMAGE_PATH, SEMANTIC_MASK_PATH, 'train', transform=transform)\n",
    "val_dataset = VOC2012Dataset(DATASET_PATH, IMAGE_PATH, SEMANTIC_MASK_PATH, 'val', transform=transform)\n",
    "\n",
    "print('Train dataset size:', len(train_dataset))\n",
    "print('Val dataset size:', len(val_dataset))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKER)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKER)\n",
    "\n",
    "# Iterate over the train dataloader\n",
    "for images, masks in train_dataloader:\n",
    "    print('Train batch size:', images.size())\n",
    "    break\n",
    "\n",
    "# Iterate over the val dataloader\n",
    "for images, masks in val_dataloader:\n",
    "    print('Val batch size:', images.size())\n",
    "    break\n",
    "\n",
    "for idx, (image, mask) in enumerate(train_dataset):\n",
    "    print('Image shape:', image.shape)\n",
    "    print('Mask shape:', mask.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = VanillaUNet(in_channels=3, out_channels=NUM_CLASSES)\n",
    "\n",
    "if SEL_CRITERION == 'CrossEntropyLoss':\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "elif SEL_CRITERION == 'BCEWithLogitsLoss':\n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "if SEL_OPTIMIZER == 'Adam':\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "elif SEL_OPTIMIZER == 'AdamW':\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "elif SEL_OPTIMIZER == 'SGD':\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "if SEL_SCHEDULER == 'ReduceLROnPlateau':\n",
    "    lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=SCH_FACTOR, patience=SCH_PATIENCE, cooldown=SCH_COOLDOWN)\n",
    "\n",
    "device = torch.device(f'cuda:{GPU_ID}' if torch.cuda.is_available() else 'cpu')\n",
    "early_stopper = EarlyStopper(patience = int(ES_PATIENCE), \n",
    "                            min_delta = float(ES_MIN_DELTA))\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f'Epoch {epoch + 1}/{NUM_EPOCHS}')\n",
    "    train_loss, train_dice_loss, train_dice_metrics = train_one_epoch(model, train_dataloader, criterion, optimizer, device)\n",
    "    print(f'Train Loss: {train_loss} | Dice loss: {train_dice_loss} | Dice metrics: {train_dice_metrics}')\n",
    "    val_loss, val_dice_loss, val_dice_metrics = evaluate(model, val_dataloader, criterion, device)\n",
    "    print(f'Val Loss: {val_loss} | Dice loss: {val_dice_loss} | Dice metrics: {val_dice_metrics}')\n",
    "    \n",
    "    lr_scheduler.step(val_loss)\n",
    "\n",
    "    # Save the model\n",
    "    if train_loss < BEST_TRAIN_LOSS:\n",
    "        saveModel(model, optimizer, lr_scheduler, epoch, train_loss, 'checkpoints/best_train.pth')\n",
    "    if val_loss < BEST_VAL_LOSS:\n",
    "        saveModel(model, optimizer, lr_scheduler, epoch, val_loss, 'checkpoints/best_val.pth')\n",
    "\n",
    "    if early_stopper.early_stop(val_loss):\n",
    "        print('Early stopping')\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_confusion_matrix(pred, target, num_classes):\n",
    "    # print(pred.shape, target.shape)\n",
    "    pred = pred.flatten()\n",
    "    target = target.flatten()\n",
    "    mask = (target >= 0) & (target < num_classes)\n",
    "    # print(pred.shape, mask.shape, target.shape)\n",
    "    return np.bincount(\n",
    "        num_classes * target[mask].astype(int) + pred[mask].astype(int),\n",
    "        minlength=num_classes**2,\n",
    "    ).reshape(num_classes, num_classes)\n",
    "\n",
    "def calculate_metrics(confusion_matrix):\n",
    "    tp = np.diag(confusion_matrix)\n",
    "    sum_rows = confusion_matrix.sum(axis=1)\n",
    "    sum_cols = confusion_matrix.sum(axis=0)\n",
    "    total_pixels = confusion_matrix.sum()\n",
    "\n",
    "    pixel_accuracy = tp.sum() / total_pixels\n",
    "    mean_pixel_accuracy = np.mean(tp / np.maximum(sum_rows, 1))\n",
    "    iou = tp / np.maximum(sum_rows + sum_cols - tp, 1)\n",
    "    mean_iou = np.mean(iou)\n",
    "\n",
    "    return pixel_accuracy, mean_pixel_accuracy, iou, mean_iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, val_loader, device, num_classes):\n",
    "    model.eval()\n",
    "    confusion_matrix = np.zeros((num_classes, num_classes), dtype=np.int64)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, masks in val_loader:\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            # preds = outputs\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            masks = torch.argmax(masks, dim=1)\n",
    "\n",
    "            for pred, mask in zip(preds, masks):\n",
    "                cm = compute_confusion_matrix(\n",
    "                    pred.cpu().numpy(),\n",
    "                    mask.cpu().numpy(),\n",
    "                    num_classes=num_classes\n",
    "                )\n",
    "                confusion_matrix += cm\n",
    "\n",
    "    pixel_accuracy, mean_pixel_accuracy, iou, mean_iou = calculate_metrics(confusion_matrix)\n",
    "    print(f\"Pixel Accuracy: {pixel_accuracy:.4f}\")\n",
    "    print(f\"Mean Pixel Accuracy: {mean_pixel_accuracy:.4f}\")\n",
    "    print(f\"Mean IoU: {mean_iou:.4f}\")\n",
    "    print(f\"IoU per Class: {iou}\")\n",
    "\n",
    "    return pixel_accuracy, mean_pixel_accuracy, iou, mean_iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(model, val_dataloader, device=device, num_classes=NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trained = VanillaUNet(in_channels=3, out_channels=NUM_CLASSES)\n",
    "model_trained.load_state_dict(torch.load('checkpoints/best_val.pth')['model_state_dict'])\n",
    "model_trained.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for images, masks in val_dataloader:\n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device)\n",
    "        \n",
    "        outputs = model_trained(images)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = images[0].permute(1, 2, 0).cpu()\n",
    "mask = masks[0].argmax(dim=0).cpu().numpy()\n",
    "predicted_mask = outputs[0].argmax(dim=0).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.title('Image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(mask)\n",
    "plt.axis('off')\n",
    "plt.title('Mask')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(predicted_mask)\n",
    "plt.axis('off')\n",
    "plt.title('Predicted Mask')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "train",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
