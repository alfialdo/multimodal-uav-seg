{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# import argparse\n",
    "import numpy as np\n",
    "import PIL.Image as Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchsummary import summary\n",
    "\n",
    "from dataset.uav_segmentation import UAVSegmentation\n",
    "from model.vanilla_unet import VanillaUNetDoubleConv as VanillaUNet\n",
    "from trainer import train_one_epoch\n",
    "from eval import evaluate\n",
    "from utils import EarlyStopper\n",
    "from utils import saveModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH_TRAIN = '/mnt/hdd/dataset/uav_dataset/train/'\n",
    "DATASET_PATH_VAL = '/mnt/hdd/dataset/uav_dataset/val/'\n",
    "DATASET_PATH_TEST = '/mnt/hdd/dataset/uav_dataset/test/'\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "NUM_EPOCHS = 3\n",
    "LEARNING_RATE = 0.0001\n",
    "GPU_ID = 0\n",
    "\n",
    "NUM_CLASSES = 2\n",
    "NUM_WORKER = 30\n",
    "\n",
    "SCH_FACTOR = 0.15\n",
    "SCH_PATIENCE = 15\n",
    "SCH_COOLDOWN = 5\n",
    "\n",
    "ES_PATIENCE = 30\n",
    "ES_MIN_DELTA = 0.001\n",
    "ES_MODE = \"min\"\n",
    "\n",
    "BEST_TRAIN_LOSS = float('inf')\n",
    "BEST_VAL_LOSS = float('inf')\n",
    "\n",
    "SEL_CRITERION = \"CrossEntropyLoss\"\n",
    "SEL_OPTIMIZER = \"AdamW\"\n",
    "SEL_SCHEDULER = \"ReduceLROnPlateau\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor()\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = UAVSegmentation(DATASET_PATH_TRAIN, NUM_CLASSES, transforms=transform)\n",
    "val_dataset = UAVSegmentation(DATASET_PATH_VAL, NUM_CLASSES, transforms=transform)\n",
    "test_dataset = UAVSegmentation(DATASET_PATH_TEST, NUM_CLASSES, transforms=transform)\n",
    "\n",
    "\n",
    "print('Train dataset size:', len(train_dataset))\n",
    "print('Val dataset size:', len(val_dataset))\n",
    "print('Test dataset size:', len(test_dataset))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKER)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKER)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKER)\n",
    "\n",
    "# Iterate over the train dataloader\n",
    "for images, masks in train_dataloader:\n",
    "    print('Train batch size:', images.size())\n",
    "    break\n",
    "\n",
    "# Iterate over the val dataloader\n",
    "for images, masks in val_dataloader:\n",
    "    print('Val batch size:', images.size())\n",
    "    break\n",
    "\n",
    "for idx, (image, mask) in enumerate(train_dataset):\n",
    "    print('Image shape:', image.shape)\n",
    "    print('Mask shape:', mask.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VanillaUNetDoubleConv(\n",
       "  (stage1): Sequential(\n",
       "    (0): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (1): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (ds_1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (stage2): Sequential(\n",
       "    (0): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (1): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (ds2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (stage3): Sequential(\n",
       "    (0): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (1): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (ds3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (middle): DoubleConv(\n",
       "    (double_conv): Sequential(\n",
       "      (0): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (4): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (us3): ConvTranspose2d(2048, 2048, kernel_size=(2, 2), stride=(2, 2))\n",
       "  (stage3_up): Sequential(\n",
       "    (0): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(4096, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (1): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (us2): ConvTranspose2d(512, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "  (stage2_up): Sequential(\n",
       "    (0): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (1): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (us1): ConvTranspose2d(128, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "  (stage1_up): Sequential(\n",
       "    (0): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (1): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (segmentation_head): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the model\n",
    "model = VanillaUNet(in_channels=1, out_channels=NUM_CLASSES)\n",
    "\n",
    "if SEL_CRITERION == 'CrossEntropyLoss':\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "elif SEL_CRITERION == 'BCEWithLogitsLoss':\n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "if SEL_OPTIMIZER == 'Adam':\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "elif SEL_OPTIMIZER == 'AdamW':\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "elif SEL_OPTIMIZER == 'SGD':\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "if SEL_SCHEDULER == 'ReduceLROnPlateau':\n",
    "    lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=SCH_FACTOR, patience=SCH_PATIENCE, cooldown=SCH_COOLDOWN)\n",
    "\n",
    "device = torch.device(f'cuda:{GPU_ID}' if torch.cuda.is_available() else 'cpu')\n",
    "early_stopper = EarlyStopper(patience = int(ES_PATIENCE), \n",
    "                            min_delta = float(ES_MIN_DELTA))\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 224, 224]             576\n",
      "       BatchNorm2d-2         [-1, 64, 224, 224]             128\n",
      "              ReLU-3         [-1, 64, 224, 224]               0\n",
      "            Conv2d-4         [-1, 64, 224, 224]          36,864\n",
      "       BatchNorm2d-5         [-1, 64, 224, 224]             128\n",
      "              ReLU-6         [-1, 64, 224, 224]               0\n",
      "        DoubleConv-7         [-1, 64, 224, 224]               0\n",
      "            Conv2d-8        [-1, 128, 224, 224]          73,728\n",
      "       BatchNorm2d-9        [-1, 128, 224, 224]             256\n",
      "             ReLU-10        [-1, 128, 224, 224]               0\n",
      "           Conv2d-11        [-1, 128, 224, 224]         147,456\n",
      "      BatchNorm2d-12        [-1, 128, 224, 224]             256\n",
      "             ReLU-13        [-1, 128, 224, 224]               0\n",
      "       DoubleConv-14        [-1, 128, 224, 224]               0\n",
      "        MaxPool2d-15        [-1, 128, 112, 112]               0\n",
      "           Conv2d-16        [-1, 256, 112, 112]         294,912\n",
      "      BatchNorm2d-17        [-1, 256, 112, 112]             512\n",
      "             ReLU-18        [-1, 256, 112, 112]               0\n",
      "           Conv2d-19        [-1, 256, 112, 112]         589,824\n",
      "      BatchNorm2d-20        [-1, 256, 112, 112]             512\n",
      "             ReLU-21        [-1, 256, 112, 112]               0\n",
      "       DoubleConv-22        [-1, 256, 112, 112]               0\n",
      "           Conv2d-23        [-1, 512, 112, 112]       1,179,648\n",
      "      BatchNorm2d-24        [-1, 512, 112, 112]           1,024\n",
      "             ReLU-25        [-1, 512, 112, 112]               0\n",
      "           Conv2d-26        [-1, 512, 112, 112]       2,359,296\n",
      "      BatchNorm2d-27        [-1, 512, 112, 112]           1,024\n",
      "             ReLU-28        [-1, 512, 112, 112]               0\n",
      "       DoubleConv-29        [-1, 512, 112, 112]               0\n",
      "        MaxPool2d-30          [-1, 512, 56, 56]               0\n",
      "           Conv2d-31         [-1, 1024, 56, 56]       4,718,592\n",
      "      BatchNorm2d-32         [-1, 1024, 56, 56]           2,048\n",
      "             ReLU-33         [-1, 1024, 56, 56]               0\n",
      "           Conv2d-34         [-1, 1024, 56, 56]       9,437,184\n",
      "      BatchNorm2d-35         [-1, 1024, 56, 56]           2,048\n",
      "             ReLU-36         [-1, 1024, 56, 56]               0\n",
      "       DoubleConv-37         [-1, 1024, 56, 56]               0\n",
      "           Conv2d-38         [-1, 2048, 56, 56]      18,874,368\n",
      "      BatchNorm2d-39         [-1, 2048, 56, 56]           4,096\n",
      "             ReLU-40         [-1, 2048, 56, 56]               0\n",
      "           Conv2d-41         [-1, 2048, 56, 56]      37,748,736\n",
      "      BatchNorm2d-42         [-1, 2048, 56, 56]           4,096\n",
      "             ReLU-43         [-1, 2048, 56, 56]               0\n",
      "       DoubleConv-44         [-1, 2048, 56, 56]               0\n",
      "        MaxPool2d-45         [-1, 2048, 28, 28]               0\n",
      "           Conv2d-46         [-1, 2048, 28, 28]      37,748,736\n",
      "      BatchNorm2d-47         [-1, 2048, 28, 28]           4,096\n",
      "             ReLU-48         [-1, 2048, 28, 28]               0\n",
      "           Conv2d-49         [-1, 2048, 28, 28]      37,748,736\n",
      "      BatchNorm2d-50         [-1, 2048, 28, 28]           4,096\n",
      "             ReLU-51         [-1, 2048, 28, 28]               0\n",
      "       DoubleConv-52         [-1, 2048, 28, 28]               0\n",
      "  ConvTranspose2d-53         [-1, 2048, 56, 56]      16,779,264\n",
      "           Conv2d-54         [-1, 1024, 56, 56]      37,748,736\n",
      "      BatchNorm2d-55         [-1, 1024, 56, 56]           2,048\n",
      "             ReLU-56         [-1, 1024, 56, 56]               0\n",
      "           Conv2d-57         [-1, 1024, 56, 56]       9,437,184\n",
      "      BatchNorm2d-58         [-1, 1024, 56, 56]           2,048\n",
      "             ReLU-59         [-1, 1024, 56, 56]               0\n",
      "       DoubleConv-60         [-1, 1024, 56, 56]               0\n",
      "           Conv2d-61          [-1, 512, 56, 56]       4,718,592\n",
      "      BatchNorm2d-62          [-1, 512, 56, 56]           1,024\n",
      "             ReLU-63          [-1, 512, 56, 56]               0\n",
      "           Conv2d-64          [-1, 512, 56, 56]       2,359,296\n",
      "      BatchNorm2d-65          [-1, 512, 56, 56]           1,024\n",
      "             ReLU-66          [-1, 512, 56, 56]               0\n",
      "       DoubleConv-67          [-1, 512, 56, 56]               0\n",
      "  ConvTranspose2d-68        [-1, 512, 112, 112]       1,049,088\n",
      "           Conv2d-69        [-1, 256, 112, 112]       2,359,296\n",
      "      BatchNorm2d-70        [-1, 256, 112, 112]             512\n",
      "             ReLU-71        [-1, 256, 112, 112]               0\n",
      "           Conv2d-72        [-1, 256, 112, 112]         589,824\n",
      "      BatchNorm2d-73        [-1, 256, 112, 112]             512\n",
      "             ReLU-74        [-1, 256, 112, 112]               0\n",
      "       DoubleConv-75        [-1, 256, 112, 112]               0\n",
      "           Conv2d-76        [-1, 128, 112, 112]         294,912\n",
      "      BatchNorm2d-77        [-1, 128, 112, 112]             256\n",
      "             ReLU-78        [-1, 128, 112, 112]               0\n",
      "           Conv2d-79        [-1, 128, 112, 112]         147,456\n",
      "      BatchNorm2d-80        [-1, 128, 112, 112]             256\n",
      "             ReLU-81        [-1, 128, 112, 112]               0\n",
      "       DoubleConv-82        [-1, 128, 112, 112]               0\n",
      "  ConvTranspose2d-83        [-1, 128, 224, 224]          65,664\n",
      "           Conv2d-84         [-1, 64, 224, 224]         147,456\n",
      "      BatchNorm2d-85         [-1, 64, 224, 224]             128\n",
      "             ReLU-86         [-1, 64, 224, 224]               0\n",
      "           Conv2d-87         [-1, 64, 224, 224]          36,864\n",
      "      BatchNorm2d-88         [-1, 64, 224, 224]             128\n",
      "             ReLU-89         [-1, 64, 224, 224]               0\n",
      "       DoubleConv-90         [-1, 64, 224, 224]               0\n",
      "           Conv2d-91         [-1, 32, 224, 224]          18,432\n",
      "      BatchNorm2d-92         [-1, 32, 224, 224]              64\n",
      "             ReLU-93         [-1, 32, 224, 224]               0\n",
      "           Conv2d-94         [-1, 32, 224, 224]           9,216\n",
      "      BatchNorm2d-95         [-1, 32, 224, 224]              64\n",
      "             ReLU-96         [-1, 32, 224, 224]               0\n",
      "       DoubleConv-97         [-1, 32, 224, 224]               0\n",
      "           Conv2d-98          [-1, 2, 224, 224]              66\n",
      "================================================================\n",
      "Total params: 226,752,386\n",
      "Trainable params: 226,752,386\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.19\n",
      "Forward/backward pass size (MB): 2585.52\n",
      "Params size (MB): 864.99\n",
      "Estimated Total Size (MB): 3450.70\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, (1, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f'Epoch {epoch + 1}/{NUM_EPOCHS}')\n",
    "    train_loss, train_dice_loss, train_dice_metrics = train_one_epoch(model, train_dataloader, criterion, optimizer, device)\n",
    "    print(f'Train Loss: {train_loss} | Dice loss: {train_dice_loss} | Dice metrics: {train_dice_metrics}')\n",
    "    val_loss, val_dice_loss, val_dice_metrics = evaluate(model, val_dataloader, criterion, device)\n",
    "    print(f'Val Loss: {val_loss} | Dice loss: {val_dice_loss} | Dice metrics: {val_dice_metrics}')\n",
    "    \n",
    "    lr_scheduler.step(val_loss)\n",
    "\n",
    "    # Save the model\n",
    "    if train_loss < BEST_TRAIN_LOSS:\n",
    "        saveModel(model, optimizer, lr_scheduler, epoch, train_loss, 'checkpoints/best_train.pth')\n",
    "    if val_loss < BEST_VAL_LOSS:\n",
    "        saveModel(model, optimizer, lr_scheduler, epoch, val_loss, 'checkpoints/best_val.pth')\n",
    "\n",
    "    if early_stopper.early_stop(val_loss):\n",
    "        print('Early stopping')\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_confusion_matrix(pred, target, num_classes):\n",
    "    # print(pred.shape, target.shape)\n",
    "    pred = pred.flatten()\n",
    "    target = target.flatten()\n",
    "    mask = (target >= 0) & (target < num_classes)\n",
    "    # print(pred.shape, mask.shape, target.shape)\n",
    "    return np.bincount(\n",
    "        num_classes * target[mask].astype(int) + pred[mask].astype(int),\n",
    "        minlength=num_classes**2,\n",
    "    ).reshape(num_classes, num_classes)\n",
    "\n",
    "def calculate_metrics(confusion_matrix):\n",
    "    tp = np.diag(confusion_matrix)\n",
    "    sum_rows = confusion_matrix.sum(axis=1)\n",
    "    sum_cols = confusion_matrix.sum(axis=0)\n",
    "    total_pixels = confusion_matrix.sum()\n",
    "\n",
    "    pixel_accuracy = tp.sum() / total_pixels\n",
    "    mean_pixel_accuracy = np.mean(tp / np.maximum(sum_rows, 1))\n",
    "    iou = tp / np.maximum(sum_rows + sum_cols - tp, 1)\n",
    "    mean_iou = np.mean(iou)\n",
    "\n",
    "    return pixel_accuracy, mean_pixel_accuracy, iou, mean_iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, val_loader, device, num_classes):\n",
    "    model.eval()\n",
    "    confusion_matrix = np.zeros((num_classes, num_classes), dtype=np.int64)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, masks in val_loader:\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            # preds = outputs\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            masks = torch.argmax(masks, dim=1)\n",
    "\n",
    "            for pred, mask in zip(preds, masks):\n",
    "                cm = compute_confusion_matrix(\n",
    "                    pred.cpu().numpy(),\n",
    "                    mask.cpu().numpy(),\n",
    "                    num_classes=num_classes\n",
    "                )\n",
    "                confusion_matrix += cm\n",
    "\n",
    "    pixel_accuracy, mean_pixel_accuracy, iou, mean_iou = calculate_metrics(confusion_matrix)\n",
    "    print(f\"Pixel Accuracy: {pixel_accuracy:.4f}\")\n",
    "    print(f\"Mean Pixel Accuracy: {mean_pixel_accuracy:.4f}\")\n",
    "    print(f\"Mean IoU: {mean_iou:.4f}\")\n",
    "    print(f\"IoU per Class: {iou}\")\n",
    "\n",
    "    return pixel_accuracy, mean_pixel_accuracy, iou, mean_iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(model, val_dataloader, device=device, num_classes=NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trained = VanillaUNet(in_channels=3, out_channels=NUM_CLASSES)\n",
    "model_trained.load_state_dict(torch.load('checkpoints/best_val.pth')['model_state_dict'])\n",
    "model_trained.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for images, masks in val_dataloader:\n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device)\n",
    "        \n",
    "        outputs = model_trained(images)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = images[0].permute(1, 2, 0).cpu()\n",
    "mask = masks[0].argmax(dim=0).cpu().numpy()\n",
    "predicted_mask = outputs[0].argmax(dim=0).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.title('Image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(mask)\n",
    "plt.axis('off')\n",
    "plt.title('Mask')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(predicted_mask)\n",
    "plt.axis('off')\n",
    "plt.title('Predicted Mask')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "train",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
